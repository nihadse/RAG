res = collection.query(
    query_texts=["A9455"],
    n_results=500,
    include=['documents', 'metadatas', 'distances']
)
print("Returned ids count:", len(res['documents'][0]))
print("Top 5 excerpts:", [doc[:120].replace("\n", " ") for doc in res['documents'][0][:5]])
print("Distances top 5:", res.get('distances', [None])[0][:5])




# RÃ©cupÃ©rer documents/metadata pour inspection (limiter pour mÃ©moire)
docs = collection.get(include=['documents', 'metadatas'], limit=1000)  # augmente si besoin

found = []
for i, doc in enumerate(docs['documents']):
    if 'A9455' in doc or 'a9455' in doc:
        found.append((i, docs['metadatas'][i], doc[:400]))  # affiche un extrait

if found:
    print(f"TrouvÃ© {len(found)} chunk(s) contenant 'A9455'. Extraits :")
    for idx, meta, excerpt in found:
        print("Index:", idx, "Metadata:", meta)
        print(excerpt)
else:
    print("Aucun chunk textuel contenant 'A9455' parmi les documents rÃ©cupÃ©rÃ©s.")











prompt = f"""
Vous Ãªtes un assistant RAG spÃ©cialisÃ© dans les systÃ¨mes bancaires, 
lâ€™architecture de donnÃ©es, et les produits financiers du groupe. 
Votre rÃ´le est de **rÃ©pondre et dâ€™expliquer clairement** les informations issues des documents,
en les rendant comprÃ©hensibles pour tout type dâ€™utilisateur, du plus gÃ©nÃ©ral au plus technique.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[CONTEXTE DOCUMENTAIRE]
{context_text}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[REQUÃŠTE UTILISATEUR]
{query}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[INSTRUCTIONS GÃ‰NÃ‰RALES]

1. Utilisez exclusivement les informations prÃ©sentes dans le contexte ci-dessus.
2. Fournissez une **rÃ©ponse claire, structurÃ©e et expliquÃ©e**, adaptÃ©e Ã  la comprÃ©hension de tout utilisateur.
   - Si le sujet est technique, expliquez les notions en termes simples.
   - Si la question est gÃ©nÃ©rale, donnez une rÃ©ponse complÃ¨te mais concise.
   - Si la question est complexe, dÃ©taillez le raisonnement et le fonctionnement.
3. Chaque fois que vous mentionnez une donnÃ©e, un mÃ©canisme ou un fait,
   citez immÃ©diatement la source sous le format :
   [Source: <nom_du_fichier>.pdf, Page <numÃ©ro>].
4. Si lâ€™information nâ€™existe pas dans les documents :
   Ã©crivez exactement : â€œInformation non disponible dans les documents consultÃ©s.â€
5. Structure attendue :
   a. **RÃ©ponse expliquÃ©e**
      - DÃ©taillez le contenu et son interprÃ©tation.
   b. **SynthÃ¨se (si utile)**
      - RÃ©sumez la logique ou le fonctionnement global.
   c. **Sources**
      - Liste complÃ¨te des documents utilisÃ©s.
6. Objectif :
   Rendre la rÃ©ponse Ã  la fois informative, explicative et vÃ©rifiable,
   quâ€™il sâ€™agisse dâ€™un utilisateur curieux ou dâ€™un expert technique.
"""


from PyPDF2 import PdfReader, PdfWriter

input_pdf = "input.pdf"
output_pdf = "page_3.pdf"

page_index = 2  # 0 = first page, so 2 = third page

reader = PdfReader(input_pdf)
writer = PdfWriter()

writer.add_page(reader.pages[page_index])

with open(output_pdf, "wb") as f:
    writer.write(f)


from collections import defaultdict

# Fetch metadata only (no vectors)
results = collection.get(include=["metadatas"])

pages_by_doc = defaultdict(set)

for meta in results["metadatas"]:
    # Ensure metadata has both doc and page
    if "source" in meta and "page" in meta:
        pages_by_doc[meta["source"]].add(meta["page"])

# Display page counts by file
total_pages = 0
for doc, pages in pages_by_doc.items():
    page_count = len(pages)
    total_pages += page_count
    print(f"{doc}: {page_count} pages")

print("\nTOTAL INDEXED PAGES IN CHROMA:", total_pages)

expected = 150_000  # your expected number
missing = expected - total_pages
print("Difference from expectation:", missing)







Les anomalies remontÃ©es par BUCC nâ€™ont aucun lien avec les lettres LR/MR


Bonjour,

Merci pour ton message.

Les donnÃ©es que nous extrayons proviennent du fichier PP dans GESKYC. AprÃ¨s une analyse approfondie, nous avons constatÃ© un changement dans le contenu de la donnÃ©e qui sert Ã  noter les informations. Les trois derniers mois, au lieu des valeurs Â« 01 / 02 / 03 Â» que nous recevions habituellement, cette colonne contient dÃ©sormais Â« 1 / 2 / 3 Â».
De plus, notre DCC contient encore les valeurs Â« 01 / 02 / 03 Â» alors que le fichier source fournit maintenant Â« 1 / 2 / 3 Â». Ces anomalies gÃ©nÃ¨rent un dÃ©calage au niveau des dÃ©tails BUCC.
Nous allons gÃ©rer cela en ajustant le DCC, en supprimant le zÃ©ro de maniÃ¨re propre et contrÃ´lÃ©e.

Cordialement,
Nihad





Bonjour,

Je te confirme quâ€™aucune modification ne sera apportÃ©e au niveau du DCC pour ce mois-ci.
Nous maintenons la version actuelle sans changement.



SELECT t1.*, t2.*, t3.*
FROM table1 AS t1
JOIN table2 AS t2
    ON t1.common_key = t2.common_key
JOIN table3 AS t3
    ON t2.other_key = t3.other_key;


import os
import streamlit as st
import httpx
from openai import AzureOpenAI

# ---- Azure config ----
API_KEY = os.getenv("AZURE_OPENAI_KEY")
API_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
API_VERSION = os.getenv("AZURE_OPENAI_API_VERSION", "2024-08-01-preview")

client = AzureOpenAI(
    azure_endpoint=API_ENDPOINT,
    api_key=API_KEY,
    api_version=API_VERSION,
)

def generate_response(query: str, context: str = "") -> str:
    prompt = (
        "[Contexte]\n"
        f"{context}\n\n"
        "[RequÃªte]\n"
        f"{query}"
    )

    with httpx.Client(verify=False) as http_client:
        try:
            completion = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are an assistant that answers people's questions clearly."},
                    {"role": "user", "content": prompt},
                ],
                temperature=0.5,
            )
            return completion.choices[0].message.content.strip()

        except Exception as e:
            return f"âš ï¸ API Error: {str(e)}"


# ---- Streamlit UI ----
st.set_page_config(page_title="Azure AI Assistant")
st.title("Azure AI Assistant")

query = st.text_input("Ask something:")

if query:
    answer = generate_response(query)
    st.write("ğŸ¤– " + answer)





Objet : Fichier dÃ©cade transmis par la BA â€“ Volume supÃ©rieur Ã  la normale

Bonjour,

Le fichier dÃ©cade transmis par la BA ce mois-ci contient 6068 noms, soit un volume supÃ©rieur Ã  la normale.
Nous avons identifiÃ© 1137 noms au-dessus du seuil de similaritÃ© (0,95) et 6068 en dessous du seuil.

Ã€ noter que des doublons sont prÃ©sents, car certains noms apparaissent Ã  la fois dans les deux listes. Cela sâ€™explique par le score de similaritÃ© : un mÃªme nom peut obtenir des scores diffÃ©rents selon les correspondances trouvÃ©es, ce qui le place parfois au-dessus et parfois en dessous du seuil.

Cordialement,







Objet : Mise Ã  jour des fichiers APA

Bonjour,

Voici la modification de lâ€™APA My Digibank â€” jâ€™ai ajoutÃ© lâ€™output ainsi que lâ€™APA V3 (APA Mass Afluent), oÃ¹ jâ€™ai intÃ©grÃ© les deux colonnes concatÃ©nÃ©es comme convenu.

Merci de confirmer que le rÃ©sultat correspond bien Ã  vos attentes.

Bien Ã  vous,
Nihad



Bonjour Nihad

Merci pour toute tes disponibilitÃ©s et ton support. Stp on a un sujet concernant l'APA de Djihane (Mass)

Deux donnÃ©es ont disparu depuis la derniÃ¨re mise a jours d'aoÃ»t qui sont nÃ©cessaire pour le dash.

Les donnÃ©es en question sont: Dernier solde et Type de compte, qui existe au 31 AoÃ»t 2025

@BECHE Khaled @KHETTABI Djihane Sakina @SENHADII Nihad afin qu'on soit tous au mÃªme niveau d'information. Je vous proper sp

APA V1 devient APA My digibank

I:\DATA EOIDEPARTEMENT_DATAIAPA Data viz11-MY DIGIBANK

APA V 3 devient APA Mass

1:\DATA EOIDEPARTEMENT DATAVAPA Data viz12-MASS AFLUENT

APA V2 sera archive car c'Ã©tait une phase intermÃ©diaire

Le rÃ©pertoire de partage I:\DATA EO\DEPARTEMENT DATALAPA Data viz est en cours de REFONTE

---

Objet : RÃ©sultats du modÃ¨le Sentinilia â€“ DÃ©tection des communautÃ©s de fraude (2024â€“2025)

Bonjour [Nom ou Ã©quipe],

Dans le cadre du suivi de notre dispositif Sentinilia, nous partageons ci-dessous les rÃ©sultats issus de la dÃ©tection des communautÃ©s de fraude pour la pÃ©riode du 02 janvier 2024 au 19 octobre 2025, basÃ©e sur les opÃ©rations extraites dâ€™Atlas.

Contrairement au premier POC limitÃ© Ã  la Turquie, cette nouvelle itÃ©ration prend en compte lâ€™ensemble des pays dans lâ€™analyse, afin dâ€™Ã©largir la couverture et dâ€™identifier de nouveaux comportements suspects Ã  lâ€™Ã©chelle globale.

Notre modÃ¨le de dÃ©tection de communautÃ©s frauduleuses (Sentinilia) repose sur des analyses de connexions entre clients prÃ©sentant des similaritÃ©s comportementales dans leurs transactions.
Les communautÃ©s ainsi dÃ©tectÃ©es regroupent des clients ayant effectuÃ© des retraits ou des opÃ©rations corrÃ©lÃ©es dans des schÃ©mas rÃ©pÃ©titifs et atypiques.

RÃ©sultats observÃ©s :

Le modÃ¨le a identifiÃ© plusieurs communautÃ©s distinctes de fraude, regroupant des ensembles de tiers diffÃ©rents, selon la pÃ©riode et les liens de comportement (voir fichier joint).

Le nombre de tiers par communautÃ© varie fortement, illustrant des structures de rÃ©seau plus ou moins denses.

Le montant total des retraits par communautÃ© prÃ©sente Ã©galement une hÃ©tÃ©rogÃ©nÃ©itÃ© significative, confirmant que les comportements suspects ne sont pas concentrÃ©s sur un seul profil, mais distribuÃ©s sur plusieurs groupes.


Fichiers joints :

Final_Resultat_groupe_2024_2025.xlsx : liste complÃ¨te des communautÃ©s dÃ©tectÃ©es par Sentinilia.

SynthÃ¨se_nb_communautÃ©s.xlsx : rÃ©capitulatif du nombre de communautÃ©s et de tiers associÃ©s.


Nous restons disponibles pour tout Ã©change complÃ©mentaire sur lâ€™interprÃ©tation des rÃ©sultats ou pour affiner les seuils dâ€™alerte selon vos retours.

Bien cordialement,
[Ton prÃ©nom / Ton nom]
Data Scientist â€“ [Nom de ton service / direction]


---

Souhaites-tu que je te reformate ce texte pour un envoi en anglais aussi (pour un partenaire ou rapport interne bilingue) ?



Aucune programmation nâ€™est impliquÃ©e : il sâ€™agit ici dâ€™un travail dâ€™analyse et de raisonnement mÃ©tier basÃ© sur la cohÃ©rence des identifiants et des relations logiques.


---

2. Objectif de lâ€™analyse

Lâ€™objectif est de reconstruire la logique de correspondance entre les deux sources afin de :

identifier les clÃ©s de correspondance fiables,

dÃ©tecter les incohÃ©rences et doublons,

comprendre la structure hiÃ©rarchique entre entitÃ©s, utilisateurs et comptes,

et Ã©valuer les limites empÃªchant une vision complÃ¨te de la base client et de son activitÃ©.



---

3. Constats et Observations

3.1. MÃ©thodologie de dÃ©tection des identifiants manquants

Au dÃ©part, plusieurs utilisateurs du fichier user prÃ©sentaient un LOCAL_IDENTIFIER manquant.
Pour corriger cela, une vÃ©rification croisÃ©e a Ã©tÃ© effectuÃ©e avec la base de donnÃ©es RMPM disponible en interne.

GrÃ¢ce Ã  cette extraction RMPM, il a Ã©tÃ© possible :

de retrouver et renseigner les identifiants locaux manquants pour la majoritÃ© des utilisateurs,

de rÃ©duire considÃ©rablement les Ã©carts entre les fichiers user et account,

bien quâ€™il subsiste quatre utilisateurs dont les identifiants locaux nâ€™ont pas pu Ãªtre retrouvÃ©s, mÃªme aprÃ¨s recherche manuelle via la plateforme AMPM Web.



---

3.2. Liaison entre User File et Account File

Le champ LOCAL_IDENTIFIER apparaÃ®t comme la clÃ© principale de correspondance entre les deux fichiers.
Cependant :

certains identifiants locaux existent dans le fichier user mais pas dans le fichier account, et inversement ;

certains identifiants locaux sont associÃ©s Ã  plusieurs ENTITY_ID, rompant la logique de correspondance unique.


Exemples :

LOCAL_IDENTIFIER = 87970058839 apparaÃ®t dans les deux fichiers mais sous des ENTITY_ID diffÃ©rents.

LOCAL_IDENTIFIER = 87000001006 (dans le fichier comptes) ne correspond pas Ã  07800000134 (dans le fichier utilisateurs).



---

3.3. CohÃ©rence logique et interprÃ©tation mÃ©tier

Un mÃªme utilisateur peut Ãªtre rattachÃ© Ã  plusieurs comptes, parfois sous des entitÃ©s diffÃ©rentes.

Le fichier account contient des comptes sans utilisateur associÃ©, pouvant correspondre Ã  :

des comptes inactifs,

des comptes issus de migrations,

ou des crÃ©ations automatiques sans rattachement utilisateur.



Ã€ lâ€™inverse, certains utilisateurs du User File nâ€™ont aucun compte associÃ©.
Ces utilisateurs prÃ©sentent nÃ©anmoins des connexions rÃ©centes, la derniÃ¨re activitÃ© observÃ©e remontant Ã  fÃ©vrier 2025, soit la pÃ©riode de lâ€™extraction.
Cela montre que leur profil est toujours actif dans Xiscash, mÃªme si aucun compte SWIFT nâ€™est visible dans le fichier comptes.

ParallÃ¨lement, plusieurs comptes orphelins apparaissent dans le fichier comptes :
leurs dates de crÃ©ation remontent Ã  2022, ce qui suggÃ¨re des ouvertures anciennes sans activitÃ© utilisateur identifiÃ©e depuis plusieurs annÃ©es.


---

3.4. IncohÃ©rences dâ€™identifiants

Plusieurs anomalies structurelles ont Ã©tÃ© relevÃ©es :

un mÃªme email utilisateur correspond Ã  plusieurs USER_ID et LOCAL_IDENTIFIER,

ex. amar.abbes@axa.de est liÃ© Ã  plusieurs identifiants locaux et entitÃ©s ;

allal@groupe-chilail.com apparaÃ®t sous plusieurs entitÃ©s avec diffÃ©rents identifiants locaux.



Cela traduit des duplications de profils ou des crÃ©ations multiples au sein de structures de groupe.


---

3.5. Chronologie de crÃ©ation des comptes

Dans le fichier account, le champ CREATE_DATE suit un schÃ©ma chronologique cohÃ©rent pour un mÃªme identifiant local :
chaque nouveau compte ajoutÃ© vient prolonger la relation existante.
Cette logique confirme une continuitÃ© dâ€™activitÃ© client au niveau du LOCAL_IDENTIFIER plutÃ´t quâ€™une crÃ©ation dâ€™utilisateurs distincts.


---

4. DifficultÃ©s dâ€™analyse

1. Filtrage par date de crÃ©ation :
Filtrer sur le CREATE_DATE dans le fichier comptes fausse les rÃ©sultats.
De nombreux liens valides disparaissent, car certains utilisateurs existent avant la crÃ©ation de leurs premiers comptes.


2. GranularitÃ© de dÃ©finition dâ€™un utilisateur :
Pour un mÃªme LOCAL_IDENTIFIER, plusieurs USER_ID existent.
Il faut donc choisir si le comptage des utilisateurs doit se baser sur le USER_ID (vue technique) ou sur le LOCAL_IDENTIFIER (vue client logique).


3. Indicateurs dâ€™activitÃ© limitÃ©s :

NB_LOG_TOTAL reprÃ©sente les connexions cumulÃ©es depuis la crÃ©ation du compte, pas sur une pÃ©riode donnÃ©e.

NB_LOG_30DAYS ne donne quâ€™une vision ponctuelle.
Pour estimer une activitÃ© trimestrielle, il faudrait disposer de plusieurs extractions consÃ©cutives.





---

5. Structures et ModÃ¨les DÃ©tectÃ©s

Lâ€™analyse rÃ©vÃ¨le les schÃ©mas suivants :

Un ENTITY_ID correspond gÃ©nÃ©ralement Ã  un MOM unique et un LOCAL_IDENTIFIER unique, mais peut regrouper plusieurs USER_ID.

Un USER_ID peut Ãªtre rattachÃ© Ã  plusieurs ENTITY_ID et LOCAL_IDENTIFIER, reflÃ©tant des droits multi-entitÃ©s (cas des utilisateurs de groupes).

Les dates de crÃ©ation dans le fichier comptes progressent de maniÃ¨re logique, confirmant la continuitÃ© client au fil du temps.



---

6. Recommandations OpÃ©rationnelles

1. Adopter le LOCAL_IDENTIFIER comme clÃ© de correspondance principale entre les deux fichiers, tout en le validant dans le pÃ©rimÃ¨tre de chaque ENTITY_ID pour Ã©viter les chevauchements entre entitÃ©s.


2. Ã‰liminer les doublons en consolidant les multiples USER_ID rattachÃ©s Ã  un mÃªme LOCAL_IDENTIFIER afin de reconstruire une vision client unifiÃ©e.


3. Ã‰tablir une cartographie complÃ¨te des correspondances entre utilisateurs et comptes :

utilisateurs sans compte,

comptes orphelins,

utilisateurs multi-entitÃ©s.



4. Mettre Ã  jour la base Xiscash en intÃ©grant les LOCAL_IDENTIFIER retrouvÃ©s via la base RMPM et en documentant les quatre cas restants non rÃ©solus aprÃ¨s vÃ©rification AMPM Web.


5. CrÃ©er un indicateur de cohÃ©rence temporelle pour identifier les comptes anciens (crÃ©Ã©s avant 2023) sans activitÃ© utilisateur rÃ©cente, et les utilisateurs actifs (fÃ©vrier 2025) sans compte associÃ©.


6. Standardiser les rÃ¨gles de crÃ©ation et de rattachement des utilisateurs dans Xiscash afin dâ€™Ã©viter les multiplicitÃ©s dâ€™identifiants entre entitÃ©s.


7. Mettre en place un tableau de bord de suivi de qualitÃ© de donnÃ©es, regroupant :

taux dâ€™utilisateurs sans compte,

taux de comptes orphelins,

doublons dÃ©tectÃ©s,

cohÃ©rence entre ENTITY_ID et LOCAL_IDENTIFIER,

activitÃ© utilisateur (connexion, derniÃ¨re date, etc.).





---

Souhaites-tu que je te le mette en version Word modifiable (mise en page professionnelle avec titres hiÃ©rarchisÃ©s, en-tÃªte et pied de page normalisÃ©s) avant de gÃ©nÃ©rer la version PDF officielle ?

