Voici lâ€™email adaptÃ© :


---

Objet : Workflow KPI Data Quality â€“ PÃ©rimÃ¨tre des donnÃ©es

Bonjour,

Voici le workflow du KPI Data Quality, incluant le pÃ©rimÃ¨tre des donnÃ©es par lignes de mÃ©tier et par domaines.

Vous trouverez le fichier au lien suivant :
[insÃ©rer le lien ici]

Bonne rÃ©ception.

Cordialement,
[Votre nom]


---

Si tu veux le rendre plus ferme ou plus neutre, je peux ajuster.






# Cas d'usage DECAD AI

Chaque mois, la Banque d'AlgÃ©rie envoie un fichier DECAD rÃ©pertoriant les Ã©metteurs de chÃ¨ques sans provision. En moyenne, ce fichier contient environ 2 200 entrÃ©es. Le fichier n'est pas structurÃ©, ce qui complique son traitement.

Les noms des clients sont souvent incohÃ©rents avec notre base de donnÃ©es clients Atlas - parfois inversÃ©s ou orthographiÃ©s diffÃ©remment. Auparavant, l'Ã©quipe des Flux Domestiques devait effectuer des recherches manuelles pour identifier les Ã©metteurs dÃ©faillants dans Atlas. C'Ã©tait chronophage, sujet aux erreurs et inefficace. Le processus DECAD AI repose sur une recherche de similaritÃ© sÃ©mantique utilisant un modÃ¨le Sentence Transformer.

## Solution DECAD AI

Nous avons dÃ©ployÃ© un systÃ¨me d'IA basÃ© sur le Traitement du Langage Naturel (NLP). En utilisant un modÃ¨le Sentence Transformer, le systÃ¨me calcule la similaritÃ© sÃ©mantique entre Atlas, notre base de donnÃ©es clients, et la liste noire de la Banque d'AlgÃ©rie.






Bien cordialement,
Nihad


---

If you want, I can also make an even snappier version thatâ€™s optimized for quick reading by your manager. Do you want me to do that?


Hereâ€™s a clean, professional version of your email with each APA point in one bullet:


---





Ã©changes de notre rÃ©union. Voici lâ€™Ã©tat de chaque APA :

APA Masse : Ajout de la donnÃ©e Code OMC tier rÃ©alisÃ©.

APA MyDigibank : Lâ€™erreur message a Ã©tÃ© corrigÃ©e, il reste Ã  tester de votre cÃ´tÃ©.

APA Connexis : Les donnÃ©es ont Ã©tÃ© ajoutÃ©es pour les portefeuilles corpo et pro, y compris la notion ayant Connexis (1/0) et la wilaya.

APA Webdoc : Les donnÃ©es ont Ã©tÃ© ajoutÃ©es pour les portefeuilles corpo et pro, y compris la notion ayant Webdoc (1/0).


Bien cordialement,
Nihad


---

If you want, I can also make a slightly more concise â€œready-to-sendâ€ French version thatâ€™s very professional and easy to skim. Do you want me to do that?






Voici la version complÃ¨te, propre, sans dÃ©tour, avec lâ€™ajout du dÃ©but que tu veux :


---

Bonjour Youcef,

Jâ€™ai annulÃ© et je remplace le dernier mail que jâ€™ai envoyÃ© hier.

Oui, je confirme que ce message reflÃ¨te fidÃ¨lement les Ã©changes de notre rÃ©union de ce matin, notamment :

â€“ APA Masse : point corrigÃ© cÃ´tÃ© DCD/client et statut en production.
â€“ Ajout du Code OMC tier : simple rajout de donnÃ©e sans modification majeure.
â€“ APA MyDigibank : sujet dâ€™erreur en cours de rÃ©solution, lancement en cours de test.
â€“ APA Connexis : reste Ã  livrer pour les portefeuilles corpo et pro, ajout de la notion Â« ayant connexis Â» (1/0) et de la wilaya.
â€“ APA Webdoc : reste Ã  livrer pour les portefeuilles corpo et pro, notion Â« ayant webdoc Â» (1/0).
â€“ Clarification attendue sur la base utilisÃ©e pour la distinction corpo/pro (catÃ©gorie, segment ou exploitant).

Bien cordialement,
Nihad SENHADJI


---

Si tu veux une version encore plus concise ou plus formelle, je peux lâ€™ajuster.




Voici une version qui dit oui, confirme que le mail reflÃ¨te bien la rÃ©union et reprend les dÃ©tails des points (APA masse, MyDigibank, Connexis, Webdoc, etc.) sans ajouter dâ€™interprÃ©tation :


---

Bonjour Youcef,

Oui, je confirme que ce message reflÃ¨te fidÃ¨lement les Ã©changes de notre rÃ©union de ce matin, notamment :

â€“ APA Masse : point corrigÃ© cÃ´tÃ© DCD/client et statut en production.
â€“ APA Massa : ajout du Code OMC tier tel que demandÃ©, simple rajout sans modification majeure.
â€“ APA MyDigibank : sujet dâ€™erreur en cours de rÃ©solution, lancement en cours de test.
â€“ APA Connexis : reste Ã  livrer pour les portefeuilles corpo et pro, ajout de la notion ayant connexis (1/0) et de la wilaya.
â€“ APA Webdoc : reste Ã  livrer pour les portefeuilles corpo et pro, notion ayant webdoc (1/0).
â€“ Clarification attendue concernant la base used pour la distinction corpo/pro (catÃ©gorie, segment ou exploitant).

Bien cordialement,
Nihad SENHADJI


---

Si tu veux je peux faire une version plus courte ou plus neutre.







Dâ€™accord, voici lâ€™explication claire de ce que Â« DONE Â» signifie dans ton Ã©change, en te basant sur le contenu exact de lâ€™email que tu mâ€™as donnÃ©.

Je te le formule comme une rÃ©ponse que tu peux envoyer Ã  ton manager, toujours en franÃ§ais, professionnelle et simple :


---

Bonjour Omar,

Pour clarification : lorsque jâ€™ai indiquÃ© Â« DONE Â» dans les rÃ©ponses en jaune, cela signifie que les points que vous aviez demandÃ©s ont Ã©tÃ© ajoutÃ©s ou traitÃ©s, conformÃ©ment Ã  ce qui a Ã©tÃ© dÃ©cidÃ© lors de la rÃ©union.

Plus prÃ©cisÃ©ment :

â€¢ APA Masse (statut en prod) :
La donnÃ©e supplÃ©mentaire Code OMC tier demandÃ©e par Youcef a Ã©tÃ© ajoutÃ©e. Aucune modification majeure nâ€™Ã©tait nÃ©cessaire â†’ DONE.

â€¢ APA Connexis (statut en cours) :
Les ajouts prÃ©vus pour le portefeuille Corporate/Pro â€” indicateur ayant connexis ou non (1/0) ainsi que la wilaya â€” ont Ã©tÃ© intÃ©grÃ©s â†’ DONE.

â€¢ APA Webdoc (statut en cours) :
Lâ€™ajout de lâ€™indicateur ayant webdoc ou non (1/0) a Ã©tÃ© effectuÃ© â†’ DONE.

Les Ã©lÃ©ments Â« DONE Â» signifient donc que les dÃ©veloppements ou mises Ã  jour demandÃ©s ont bien Ã©tÃ© rÃ©alisÃ©s de notre cÃ´tÃ©.
Comme prÃ©cisÃ©, seul APA Masse est actuellement en production ; les autres APA restent en test aprÃ¨s intÃ©gration des ajouts.

Cordialement,
Nihad


---

Tu peux lâ€™envoyer tel quel.



Voici une rÃ©ponse propre, claire et professionnelle en franÃ§ais, Ã  envoyer Ã  Omar.
Le ton est neutre, factuel, et correspond Ã  ce que tu veux dire.


---

Bonjour Omar,

Je vous confirme que tout ce que vous aviez demandÃ© aprÃ¨s notre rÃ©union a Ã©tÃ© effectuÃ©.

Les Ã©lÃ©ments demandÃ©s pour les diffÃ©rents APA ont bien Ã©tÃ© ajoutÃ©s.
Ã€ ce jour, le seul APA en production reste APA Masse ; les autres APA demeurent en phase de test suite aux ajouts rÃ©alisÃ©s.

Cordialement,
Nihad


---

Si tu veux, je peux lâ€™adapter en version plus dÃ©taillÃ©e ou plus formelle selon le contexte professionnel.





PrÃ©sence de doublons dans les deux fichiers :
â€“ Lignes utilisateurs dupliquÃ©es.
â€“ Lignes de comptes dupliquÃ©es.
â€“ Certaines duplications portent sur les identifiants clÃ©s, ce qui crÃ©e des conflits dans les correspondances.

En rÃ©sumÃ©, la base actuelle prÃ©sente des incohÃ©rences structurelles qui empÃªchent dâ€™Ã©tablir des correspondances fiables entre utilisateurs, entitÃ©s et comptes. Une clarification ou une nouvelle extraction plus propre serait nÃ©cessaire pour poursuivre le travail.

Suite Ã  cette analyse, nous avons construit une base de donnÃ©es finale structurÃ©e Ã  partir de ces deux fichiers.


voici la apa 





Voici une version rÃ©Ã©crite, fluide et professionnelle, toujours en franÃ§ais, et adaptÃ©e Ã  un email :


---

Dans le cadre du projet Connexis, nous avons analysÃ© les deux fichiers extraits en fÃ©vrier 2025 : le fichier des utilisateurs et le fichier des comptes. Lâ€™objectif Ã©tait de comprendre comment sâ€™articulent lâ€™ID national, le Local Identifier, le User ID, lâ€™Entity ID et les comptes associÃ©s, et dâ€™Ã©valuer la cohÃ©rence globale de la base.

Lâ€™analyse montre plusieurs incohÃ©rences structurelles. Certains utilisateurs apparaissent sans Local Identifier dans le fichier Users, et la mÃªme situation se retrouve cÃ´tÃ© comptes. La structure des identifiants elle-mÃªme manque de stabilitÃ© : un mÃªme ID national peut Ãªtre rattachÃ© Ã  plusieurs Entity ID et plusieurs identifiants tiers, un Entity ID peut regrouper plusieurs ID nationaux, et un Local Identifier peut apparaÃ®tre sous diffÃ©rentes entitÃ©s, ce qui complique le rapprochement logique entre les deux fichiers.

Il est important de prÃ©ciser que toute cette analyse repose exclusivement sur les deux fichiers fournis : le fichier Users et le fichier Accounts de lâ€™extraction fÃ©vrier 2025.


---

Si tu veux, je peux aussi lâ€™intÃ©grer directement dans ton email complet....














Bonjour Chaima,

Merci pour lâ€™envoi des fichiers.
Pouvez-vous Ã©galement nous transmettre les rÃ¨gles de gestion relatives aux garanties ?

Cordialement,
Nihad


reranked_chunks = reranker.rerank(query, retrieved_chunks)
context = " ".join([chunk["content"] for chunk in reranked_chunks])
completion = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "system", "content": context},
              {"role": "user", "content": query}]
)
return completion.choices[0].message.content





import string
from rank_bm25 import BM25Okapi

class BM25Reranker:
    """A document reranker using BM25 algorithm with error handling."""

    def __init__(self, k=50):
        self.k = k
        self.bm25 = None
        self.document_map = {}
        self.tokenizer = str.maketrans('', '', string.punctuation)

    def _preprocess(self, text):
        """Lowercase, remove punctuation, and split text."""
        if not isinstance(text, str):
            return []
        cleaned = text.translate(self.tokenizer).lower()
        return [t for t in cleaned.split() if t.strip()]

    def fit(self, documents):
        """Fit BM25 model on a list of documents (list of dicts)."""
        if not documents:
            raise ValueError("Empty document list given to BM25Reranker")

        tokenized_corpus = []
        valid_docs = []

        for i, doc in enumerate(documents):
            text = doc.get("text") or doc.get("page_content") or doc.get("content") or ""
            tokens = self._preprocess(text)
            if tokens:
                tokenized_corpus.append(tokens)
                valid_docs.append((i, doc))

        if not tokenized_corpus:
            raise ValueError("No valid documents to fit BM25 model")

        self.document_map = {i: doc for i, (_, doc) in enumerate(valid_docs)}
        self.bm25 = BM25Okapi(tokenized_corpus)

    def rerank(self, query, documents):
        """Rerank a list of documents using BM25 for the given query."""
        if not documents:
            return []

        self.fit(documents)
        tokens = self._preprocess(query)
        if not tokens:
            return documents[:self.k]

        scores = self.bm25.get_scores(tokens)
        ranked = sorted(
            zip(scores, self.document_map.values()), key=lambda x: x[0], reverse=True
        )

        return [doc for _, doc in ranked[:self.k]]


class CustomRetrieverWithHistory:
    """Retriever that uses Chroma and BM25 reranking with chat history support."""

    def __init__(self, collection, chat_history=None, k=50, rerank_k=50):
        self.collection = collection  # Chroma collection
        self.chat_history = chat_history or []
        self.k = k
        self.reranker = BM25Reranker(k=rerank_k)

    def get_relevant_documents(self, query):
        """Retrieve from Chroma, rerank using BM25, and return structured docs."""
        # Step 1: include chat history if available
        if self.chat_history:
            full_query = " ".join(self.chat_history) + " " + query
        else:
            full_query = query

        # Step 2: retrieve initial candidates
        results = self.collection.query(
            query_texts=[full_query],
            n_results=self.k * 5,  # fetch a larger batch for better recall
            include=["documents", "metadatas"]
        )

        # Step 3: format the output into consistent doc dictionaries
        # results["documents"] and results["metadatas"] are nested lists from Chroma
        docs = [
            {"text": doc, "metadata": meta}
            for doc, meta in zip(results["documents"][0], results["metadatas"][0])
        ]

        # Step 4: rerank using BM25
        reranked_docs = self.reranker.rerank(full_query, docs)

        # Step 5: return top reranked docs
        return reranked_docs



retriever = CustomRetrieverWithHistory(collection, chat_history=["context"], k=50, rerank_k=10)
docs = retriever.get_relevant_documents("A9455")


# Check if "A9455" is in any of your stored documents
results = collection.query(
    query_texts=["A9455"],
    n_results=5,
    include=["documents", "metadatas"]
)

for doc, meta in zip(results["documents"][0], results["metadatas"][0]):
    print("DOC:", doc)
    print("META:", meta)
    print("=" * 80)



# Retrieve *all* stored documents containing that code
all_docs = collection.get(include=["documents", "metadatas"])

found = [doc for doc in all_docs["documents"] if "A9455" in doc]
print(f"Found {len(found)} occurrences of 'A9455'")


import string
from rank_bm25 import BM25Okapi


# ------------------------------
# 1. TEXT PREPROCESSING
# ------------------------------
def preprocess_text(text: str) -> list:
    """Clean text and tokenize it into words for BM25."""
    if not isinstance(text, str):
        return []

    # Remove punctuation and lowercase everything
    tokenizer = str.maketrans('', '', string.punctuation)
    cleaned_text = text.translate(tokenizer).lower()

    # Split into words and remove empties
    return [token for token in cleaned_text.split() if token.strip()]


# ------------------------------
# 2. TRAIN BM25 ON DOCUMENTS
# ------------------------------
def fit_bm25(documents: list):
    """
    Create a BM25 model trained on document texts.
    Returns both the BM25 model and a mapping of doc indices to original docs.
    """
    if not documents:
        raise ValueError("Cannot fit BM25 with empty document list")

    tokenized_corpus = []
    valid_documents = []

    for i, doc in enumerate(documents):
        if not isinstance(doc, dict):
            continue

        # Handle possible key variations
        text = doc.get('text') or doc.get('page_content') or doc.get('content') or ""
        tokens = preprocess_text(text)

        if tokens:
            tokenized_corpus.append(tokens)
            valid_documents.append((i, doc))

    if not tokenized_corpus:
        raise ValueError("No valid documents with non-empty text for BM25 training")

    document_map = {new_id: orig_doc for new_id, (_, orig_doc) in enumerate(valid_documents)}
    bm25_model = BM25Okapi(tokenized_corpus)
    return bm25_model, document_map


# ------------------------------
# 3. RERANK DOCUMENTS USING BM25
# ------------------------------
def rerank_bm25(query: str, documents: list, k: int = 10) -> list:
    """Use BM25 to rerank a set of documents for a given query."""
    if not documents:
        return []

    bm25_model, document_map = fit_bm25(documents)

    query_tokens = preprocess_text(query)
    if not query_tokens:
        return documents[:k]

    scores = bm25_model.get_scores(query_tokens)

    # Pair each doc with its BM25 score
    scored_docs = [(score, document_map[idx]) for idx, score in enumerate(scores)]
    scored_docs.sort(reverse=True, key=lambda x: x[0])

    # Return only the top k docs
    return [doc for score, doc in scored_docs[:k]]


# ------------------------------
# 4. RETRIEVE FROM CHROMA + RERANK
# ------------------------------
def retrieve_with_bm25(collection, query: str, k: int = 50, rerank_k: int = 10) -> list:
    """
    Retrieve documents from Chroma and rerank them using BM25.
    """
    # Step 1: Retrieve initial candidate documents from Chroma
    results = collection.query(
        query_texts=[query],
        n_results=k * 10,  # pull a large batch for recall
        include=["documents", "metadatas"]
    )

    # Step 2: Format docs consistently
    docs = [{"text": doc, "metadata": meta}
            for doc, meta in zip(results["documents"][0], results["metadatas"][0])]

    # Step 3: Apply BM25 reranking
    reranked_docs = rerank_bm25(query, docs, k=rerank_k)
    return reranked_docs




import json
from rank_bm25 import BM25Okapi
import string


class BM25Reranker:
    """A document reranker using the BM25 algorithm with error handling."""

    def __init__(self, k=50):
        self.k = k
        self.bm25 = None
        self.document_map = {}
        self.tokenizer = str.maketrans('', '', string.punctuation)

    def preprocess(self, text: str):
        if not isinstance(text, str):
            return []
        cleaned_text = text.translate(self.tokenizer).lower()
        return [token for token in cleaned_text.split() if token.strip()]

    def fit(self, documents: list):
        if not documents:
            raise ValueError("Cannot fit BM25 with empty documents list")

        tokenized_corpus = []
        valid_documents = []

        for i, doc in enumerate(documents):
            if not isinstance(doc, dict):
                continue
            text = doc.get("text", "")
            tokens = self.preprocess(text)
            if tokens:
                tokenized_corpus.append(tokens)
                valid_documents.append((i, doc))

        if not tokenized_corpus:
            raise ValueError("No valid documents with non-empty text content for BM25 training")

        self.document_map = {new_id: orig_doc for new_id, (_, orig_doc) in enumerate(valid_documents)}
        self.bm25 = BM25Okapi(tokenized_corpus)
        return self

    def rerank(self, query: str, documents: list):
        if not documents:
            return []

        if not self.bm25:
            try:
                self.fit(documents)
            except Exception as e:
                print(f"BM25 fit failed: {str(e)}")
                return documents[:self.k]

        try:
            query_tokens = self.preprocess(query)
            if not query_tokens:
                return documents[:self.k]

            scores = self.bm25.get_scores(query_tokens)
            scored_docs = [(score, self.document_map[idx]) for idx, score in enumerate(scores) if idx in self.document_map]
            scored_docs.sort(reverse=True, key=lambda x: x[0])
            return [doc for score, doc in scored_docs[:self.k]]

        except Exception as e:
            print(f"BM25 reranking failed: {str(e)}")
            return documents[:self.k]


class CustomRetrieverWithHistory:
    """Retriever that integrates chat history, Chroma retrieval, and BM25 reranking."""

    def __init__(self, collection, chat_history=None, k=50, rerank_k=50):
        self.collection = collection  # Chroma collection
        self.chat_history = chat_history or []
        self.k = k
        self.reranker = BM25Reranker(k=rerank_k)

    def get_relevant_documents(self, query: str):
        """Retrieve and rerank documents with optional history-based query expansion."""
        try:
            # Step 1: Base retrieval
            results = self.collection.query(
                query_texts=[query],
                n_results=self.k * 2,
                include=["documents", "metadatas"]
            )
            docs = [
                {"text": doc, "metadata": meta}
                for doc, meta in zip(results["documents"][0], results["metadatas"][0])
            ]

            # Step 2: Enhance with recent chat history (last 3 Q&A)
            if self.chat_history:
                recent_history = self.chat_history[-3:] if len(self.chat_history) > 3 else self.chat_history
                history_context = "\n".join([f"Q: {q}\nA: {a}" for q, a in recent_history])
                enhanced_query = f"{query}\n\nRelated context:\n{history_context}"

                # Step 3: Retrieve more using enhanced query
                extra_results = self.collection.query(
                    query_texts=[enhanced_query],
                    n_results=100,
                    include=["documents", "metadatas"]
                )

                extra_docs = [
                    {"text": doc, "metadata": meta}
                    for doc, meta in zip(extra_results["documents"][0], extra_results["metadatas"][0])
                ]

                # Step 4: Merge and deduplicate
                all_docs = {d["text"]: d for d in docs + extra_docs}
                docs = list(all_docs.values())

            # Step 5: Rerank with BM25
            return self.reranker.rerank(query, docs)

        except Exception as e:
            print(f"Error during retrieval: {str(e)}")
            return []

    def update_history(self, query: str, answer: str):
        """Add query-answer pair to memory."""
        self.chat_history.append((query, answer))

    def save_history(self, file_path="bank_rag_state.json"):
        """Save chat history to disk."""
        try:
            state = {"chat_history": self.chat_history}
            with open(file_path, "w", encoding="utf-8") as f:
                json.dump(state, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"Error saving history: {str(e)}")

    def load_history(self, file_path="bank_rag_state.json"):
        """Load chat history from disk."""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                state = json.load(f)
            self.chat_history = state.get("chat_history", [])
            print(f"Loaded {len(self.chat_history)} previous conversations.")
        except FileNotFoundError:
            print("No previous history found.")
        except Exception as e:
            print(f"Error loading history: {str(e)}")




import string
from rank_bm25 import BM25Okapi

class BM25Reranker:
    """A document reranker using the BM25 algorithm."""

    def __init__(self, k=50):
        self.k = k
        self.bm25 = None
        self.document_map = {}
        self.tokenizer = str.maketrans('', '', string.punctuation)

    def preprocess(self, text: str):
        if not isinstance(text, str):
            return []
        cleaned_text = text.translate(self.tokenizer).lower()
        return [token for token in cleaned_text.split() if token.strip()]

    def fit(self, documents: list):
        if not documents:
            raise ValueError("Cannot fit BM25 with empty documents list")

        tokenized_corpus = []
        valid_documents = []

        for i, doc in enumerate(documents):
            if not isinstance(doc, dict):
                continue
            text = doc.get("text", "")
            tokens = self.preprocess(text)
            if tokens:
                tokenized_corpus.append(tokens)
                valid_documents.append((i, doc))

        if not tokenized_corpus:
            raise ValueError("No valid documents with non-empty text content for BM25 training")

        self.document_map = {new_id: orig_doc for new_id, (_, orig_doc) in enumerate(valid_documents)}
        self.bm25 = BM25Okapi(tokenized_corpus)
        return self

    def rerank(self, query: str, documents: list):
        if not documents:
            return []

        if not self.bm25:
            try:
                self.fit(documents)
            except Exception as e:
                print(f"BM25 fit failed: {str(e)}")
                return documents[:self.k]

        try:
            query_tokens = self.preprocess(query)
            if not query_tokens:
                return documents[:self.k]

            scores = self.bm25.get_scores(query_tokens)
            scored_docs = [(score, self.document_map[idx]) for idx, score in enumerate(scores) if idx in self.document_map]
            scored_docs.sort(reverse=True, key=lambda x: x[0])
            return [doc for score, doc in scored_docs[:self.k]]

        except Exception as e:
            print(f"BM25 reranking failed: {str(e)}")
            return documents[:self.k]







res = collection.query(
    query_texts=["A9455"],
    n_results=500,
    include=['documents', 'metadatas', 'distances']
)
print("Returned ids count:", len(res['documents'][0]))
print("Top 5 excerpts:", [doc[:120].replace("\n", " ") for doc in res['documents'][0][:5]])
print("Distances top 5:", res.get('distances', [None])[0][:5])




# RÃ©cupÃ©rer documents/metadata pour inspection (limiter pour mÃ©moire)
docs = collection.get(include=['documents', 'metadatas'], limit=1000)  # augmente si besoin

found = []
for i, doc in enumerate(docs['documents']):
    if 'A9455' in doc or 'a9455' in doc:
        found.append((i, docs['metadatas'][i], doc[:400]))  # affiche un extrait

if found:
    print(f"TrouvÃ© {len(found)} chunk(s) contenant 'A9455'. Extraits :")
    for idx, meta, excerpt in found:
        print("Index:", idx, "Metadata:", meta)
        print(excerpt)
else:
    print("Aucun chunk textuel contenant 'A9455' parmi les documents rÃ©cupÃ©rÃ©s.")











prompt = f"""
Vous Ãªtes un assistant RAG spÃ©cialisÃ© dans les systÃ¨mes bancaires, 
lâ€™architecture de donnÃ©es, et les produits financiers du groupe. 
Votre rÃ´le est de **rÃ©pondre et dâ€™expliquer clairement** les informations issues des documents,
en les rendant comprÃ©hensibles pour tout type dâ€™utilisateur, du plus gÃ©nÃ©ral au plus technique.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[CONTEXTE DOCUMENTAIRE]
{context_text}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[REQUÃŠTE UTILISATEUR]
{query}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[INSTRUCTIONS GÃ‰NÃ‰RALES]

1. Utilisez exclusivement les informations prÃ©sentes dans le contexte ci-dessus.
2. Fournissez une **rÃ©ponse claire, structurÃ©e et expliquÃ©e**, adaptÃ©e Ã  la comprÃ©hension de tout utilisateur.
   - Si le sujet est technique, expliquez les notions en termes simples.
   - Si la question est gÃ©nÃ©rale, donnez une rÃ©ponse complÃ¨te mais concise.
   - Si la question est complexe, dÃ©taillez le raisonnement et le fonctionnement.
3. Chaque fois que vous mentionnez une donnÃ©e, un mÃ©canisme ou un fait,
   citez immÃ©diatement la source sous le format :
   [Source: <nom_du_fichier>.pdf, Page <numÃ©ro>].
4. Si lâ€™information nâ€™existe pas dans les documents :
   Ã©crivez exactement : â€œInformation non disponible dans les documents consultÃ©s.â€
5. Structure attendue :
   a. **RÃ©ponse expliquÃ©e**
      - DÃ©taillez le contenu et son interprÃ©tation.
   b. **SynthÃ¨se (si utile)**
      - RÃ©sumez la logique ou le fonctionnement global.
   c. **Sources**
      - Liste complÃ¨te des documents utilisÃ©s.
6. Objectif :
   Rendre la rÃ©ponse Ã  la fois informative, explicative et vÃ©rifiable,
   quâ€™il sâ€™agisse dâ€™un utilisateur curieux ou dâ€™un expert technique.
"""


from PyPDF2 import PdfReader, PdfWriter

input_pdf = "input.pdf"
output_pdf = "page_3.pdf"

page_index = 2  # 0 = first page, so 2 = third page

reader = PdfReader(input_pdf)
writer = PdfWriter()

writer.add_page(reader.pages[page_index])

with open(output_pdf, "wb") as f:
    writer.write(f)


from collections import defaultdict

# Fetch metadata only (no vectors)
results = collection.get(include=["metadatas"])

pages_by_doc = defaultdict(set)

for meta in results["metadatas"]:
    # Ensure metadata has both doc and page
    if "source" in meta and "page" in meta:
        pages_by_doc[meta["source"]].add(meta["page"])

# Display page counts by file
total_pages = 0
for doc, pages in pages_by_doc.items():
    page_count = len(pages)
    total_pages += page_count
    print(f"{doc}: {page_count} pages")

print("\nTOTAL INDEXED PAGES IN CHROMA:", total_pages)

expected = 150_000  # your expected number
missing = expected - total_pages
print("Difference from expectation:", missing)







Les anomalies remontÃ©es par BUCC nâ€™ont aucun lien avec les lettres LR/MR


Bonjour,

Merci pour ton message.

Les donnÃ©es que nous extrayons proviennent du fichier PP dans GESKYC. AprÃ¨s une analyse approfondie, nous avons constatÃ© un changement dans le contenu de la donnÃ©e qui sert Ã  noter les informations. Les trois derniers mois, au lieu des valeurs Â« 01 / 02 / 03 Â» que nous recevions habituellement, cette colonne contient dÃ©sormais Â« 1 / 2 / 3 Â».
De plus, notre DCC contient encore les valeurs Â« 01 / 02 / 03 Â» alors que le fichier source fournit maintenant Â« 1 / 2 / 3 Â». Ces anomalies gÃ©nÃ¨rent un dÃ©calage au niveau des dÃ©tails BUCC.
Nous allons gÃ©rer cela en ajustant le DCC, en supprimant le zÃ©ro de maniÃ¨re propre et contrÃ´lÃ©e.

Cordialement,
Nihad





Bonjour,

Je te confirme quâ€™aucune modification ne sera apportÃ©e au niveau du DCC pour ce mois-ci.
Nous maintenons la version actuelle sans changement.



SELECT t1.*, t2.*, t3.*
FROM table1 AS t1
JOIN table2 AS t2
    ON t1.common_key = t2.common_key
JOIN table3 AS t3
    ON t2.other_key = t3.other_key;


import os
import streamlit as st
import httpx
from openai import AzureOpenAI

# ---- Azure config ----
API_KEY = os.getenv("AZURE_OPENAI_KEY")
API_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
API_VERSION = os.getenv("AZURE_OPENAI_API_VERSION", "2024-08-01-preview")

client = AzureOpenAI(
    azure_endpoint=API_ENDPOINT,
    api_key=API_KEY,
    api_version=API_VERSION,
)

def generate_response(query: str, context: str = "") -> str:
    prompt = (
        "[Contexte]\n"
        f"{context}\n\n"
        "[RequÃªte]\n"
        f"{query}"
    )

    with httpx.Client(verify=False) as http_client:
        try:
            completion = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are an assistant that answers people's questions clearly."},
                    {"role": "user", "content": prompt},
                ],
                temperature=0.5,
            )
            return completion.choices[0].message.content.strip()

        except Exception as e:
            return f"âš ï¸ API Error: {str(e)}"


# ---- Streamlit UI ----
st.set_page_config(page_title="Azure AI Assistant")
st.title("Azure AI Assistant")

query = st.text_input("Ask something:")

if query:
    answer = generate_response(query)
    st.write("ğŸ¤– " + answer)





Objet : Fichier dÃ©cade transmis par la BA â€“ Volume supÃ©rieur Ã  la normale

Bonjour,

Le fichier dÃ©cade transmis par la BA ce mois-ci contient 6068 noms, soit un volume supÃ©rieur Ã  la normale.
Nous avons identifiÃ© 1137 noms au-dessus du seuil de similaritÃ© (0,95) et 6068 en dessous du seuil.

Ã€ noter que des doublons sont prÃ©sents, car certains noms apparaissent Ã  la fois dans les deux listes. Cela sâ€™explique par le score de similaritÃ© : un mÃªme nom peut obtenir des scores diffÃ©rents selon les correspondances trouvÃ©es, ce qui le place parfois au-dessus et parfois en dessous du seuil.

Cordialement,







Objet : Mise Ã  jour des fichiers APA

Bonjour,

Voici la modification de lâ€™APA My Digibank â€” jâ€™ai ajoutÃ© lâ€™output ainsi que lâ€™APA V3 (APA Mass Afluent), oÃ¹ jâ€™ai intÃ©grÃ© les deux colonnes concatÃ©nÃ©es comme convenu.

Merci de confirmer que le rÃ©sultat correspond bien Ã  vos attentes.

Bien Ã  vous,
Nihad



Bonjour Nihad

Merci pour toute tes disponibilitÃ©s et ton support. Stp on a un sujet concernant l'APA de Djihane (Mass)

Deux donnÃ©es ont disparu depuis la derniÃ¨re mise a jours d'aoÃ»t qui sont nÃ©cessaire pour le dash.

Les donnÃ©es en question sont: Dernier solde et Type de compte, qui existe au 31 AoÃ»t 2025

@BECHE Khaled @KHETTABI Djihane Sakina @SENHADII Nihad afin qu'on soit tous au mÃªme niveau d'information. Je vous proper sp

APA V1 devient APA My digibank

I:\DATA EOIDEPARTEMENT_DATAIAPA Data viz11-MY DIGIBANK

APA V 3 devient APA Mass

1:\DATA EOIDEPARTEMENT DATAVAPA Data viz12-MASS AFLUENT

APA V2 sera archive car c'Ã©tait une phase intermÃ©diaire

Le rÃ©pertoire de partage I:\DATA EO\DEPARTEMENT DATALAPA Data viz est en cours de REFONTE

---

Objet : RÃ©sultats du modÃ¨le Sentinilia â€“ DÃ©tection des communautÃ©s de fraude (2024â€“2025)

Bonjour [Nom ou Ã©quipe],

Dans le cadre du suivi de notre dispositif Sentinilia, nous partageons ci-dessous les rÃ©sultats issus de la dÃ©tection des communautÃ©s de fraude pour la pÃ©riode du 02 janvier 2024 au 19 octobre 2025, basÃ©e sur les opÃ©rations extraites dâ€™Atlas.

Contrairement au premier POC limitÃ© Ã  la Turquie, cette nouvelle itÃ©ration prend en compte lâ€™ensemble des pays dans lâ€™analyse, afin dâ€™Ã©largir la couverture et dâ€™identifier de nouveaux comportements suspects Ã  lâ€™Ã©chelle globale.

Notre modÃ¨le de dÃ©tection de communautÃ©s frauduleuses (Sentinilia) repose sur des analyses de connexions entre clients prÃ©sentant des similaritÃ©s comportementales dans leurs transactions.
Les communautÃ©s ainsi dÃ©tectÃ©es regroupent des clients ayant effectuÃ© des retraits ou des opÃ©rations corrÃ©lÃ©es dans des schÃ©mas rÃ©pÃ©titifs et atypiques.

RÃ©sultats observÃ©s :

Le modÃ¨le a identifiÃ© plusieurs communautÃ©s distinctes de fraude, regroupant des ensembles de tiers diffÃ©rents, selon la pÃ©riode et les liens de comportement (voir fichier joint).

Le nombre de tiers par communautÃ© varie fortement, illustrant des structures de rÃ©seau plus ou moins denses.

Le montant total des retraits par communautÃ© prÃ©sente Ã©galement une hÃ©tÃ©rogÃ©nÃ©itÃ© significative, confirmant que les comportements suspects ne sont pas concentrÃ©s sur un seul profil, mais distribuÃ©s sur plusieurs groupes.


Fichiers joints :

Final_Resultat_groupe_2024_2025.xlsx : liste complÃ¨te des communautÃ©s dÃ©tectÃ©es par Sentinilia.

SynthÃ¨se_nb_communautÃ©s.xlsx : rÃ©capitulatif du nombre de communautÃ©s et de tiers associÃ©s.


Nous restons disponibles pour tout Ã©change complÃ©mentaire sur lâ€™interprÃ©tation des rÃ©sultats ou pour affiner les seuils dâ€™alerte selon vos retours.

Bien cordialement,
[Ton prÃ©nom / Ton nom]
Data Scientist â€“ [Nom de ton service / direction]


---

Souhaites-tu que je te reformate ce texte pour un envoi en anglais aussi (pour un partenaire ou rapport interne bilingue) ?



Aucune programmation nâ€™est impliquÃ©e : il sâ€™agit ici dâ€™un travail dâ€™analyse et de raisonnement mÃ©tier basÃ© sur la cohÃ©rence des identifiants et des relations logiques.


---

2. Objectif de lâ€™analyse

Lâ€™objectif est de reconstruire la logique de correspondance entre les deux sources afin de :

identifier les clÃ©s de correspondance fiables,

dÃ©tecter les incohÃ©rences et doublons,

comprendre la structure hiÃ©rarchique entre entitÃ©s, utilisateurs et comptes,

et Ã©valuer les limites empÃªchant une vision complÃ¨te de la base client et de son activitÃ©.



---

3. Constats et Observations

3.1. MÃ©thodologie de dÃ©tection des identifiants manquants

Au dÃ©part, plusieurs utilisateurs du fichier user prÃ©sentaient un LOCAL_IDENTIFIER manquant.
Pour corriger cela, une vÃ©rification croisÃ©e a Ã©tÃ© effectuÃ©e avec la base de donnÃ©es RMPM disponible en interne.

GrÃ¢ce Ã  cette extraction RMPM, il a Ã©tÃ© possible :

de retrouver et renseigner les identifiants locaux manquants pour la majoritÃ© des utilisateurs,

de rÃ©duire considÃ©rablement les Ã©carts entre les fichiers user et account,

bien quâ€™il subsiste quatre utilisateurs dont les identifiants locaux nâ€™ont pas pu Ãªtre retrouvÃ©s, mÃªme aprÃ¨s recherche manuelle via la plateforme AMPM Web.



---

3.2. Liaison entre User File et Account File

Le champ LOCAL_IDENTIFIER apparaÃ®t comme la clÃ© principale de correspondance entre les deux fichiers.
Cependant :

certains identifiants locaux existent dans le fichier user mais pas dans le fichier account, et inversement ;

certains identifiants locaux sont associÃ©s Ã  plusieurs ENTITY_ID, rompant la logique de correspondance unique.


Exemples :

LOCAL_IDENTIFIER = 87970058839 apparaÃ®t dans les deux fichiers mais sous des ENTITY_ID diffÃ©rents.

LOCAL_IDENTIFIER = 87000001006 (dans le fichier comptes) ne correspond pas Ã  07800000134 (dans le fichier utilisateurs).



---

3.3. CohÃ©rence logique et interprÃ©tation mÃ©tier

Un mÃªme utilisateur peut Ãªtre rattachÃ© Ã  plusieurs comptes, parfois sous des entitÃ©s diffÃ©rentes.

Le fichier account contient des comptes sans utilisateur associÃ©, pouvant correspondre Ã  :

des comptes inactifs,

des comptes issus de migrations,

ou des crÃ©ations automatiques sans rattachement utilisateur.



Ã€ lâ€™inverse, certains utilisateurs du User File nâ€™ont aucun compte associÃ©.
Ces utilisateurs prÃ©sentent nÃ©anmoins des connexions rÃ©centes, la derniÃ¨re activitÃ© observÃ©e remontant Ã  fÃ©vrier 2025, soit la pÃ©riode de lâ€™extraction.
Cela montre que leur profil est toujours actif dans Xiscash, mÃªme si aucun compte SWIFT nâ€™est visible dans le fichier comptes.

ParallÃ¨lement, plusieurs comptes orphelins apparaissent dans le fichier comptes :
leurs dates de crÃ©ation remontent Ã  2022, ce qui suggÃ¨re des ouvertures anciennes sans activitÃ© utilisateur identifiÃ©e depuis plusieurs annÃ©es.


---

3.4. IncohÃ©rences dâ€™identifiants

Plusieurs anomalies structurelles ont Ã©tÃ© relevÃ©es :

un mÃªme email utilisateur correspond Ã  plusieurs USER_ID et LOCAL_IDENTIFIER,

ex. amar.abbes@axa.de est liÃ© Ã  plusieurs identifiants locaux et entitÃ©s ;

allal@groupe-chilail.com apparaÃ®t sous plusieurs entitÃ©s avec diffÃ©rents identifiants locaux.



Cela traduit des duplications de profils ou des crÃ©ations multiples au sein de structures de groupe.


---

3.5. Chronologie de crÃ©ation des comptes

Dans le fichier account, le champ CREATE_DATE suit un schÃ©ma chronologique cohÃ©rent pour un mÃªme identifiant local :
chaque nouveau compte ajoutÃ© vient prolonger la relation existante.
Cette logique confirme une continuitÃ© dâ€™activitÃ© client au niveau du LOCAL_IDENTIFIER plutÃ´t quâ€™une crÃ©ation dâ€™utilisateurs distincts.


---

4. DifficultÃ©s dâ€™analyse

1. Filtrage par date de crÃ©ation :
Filtrer sur le CREATE_DATE dans le fichier comptes fausse les rÃ©sultats.
De nombreux liens valides disparaissent, car certains utilisateurs existent avant la crÃ©ation de leurs premiers comptes.


2. GranularitÃ© de dÃ©finition dâ€™un utilisateur :
Pour un mÃªme LOCAL_IDENTIFIER, plusieurs USER_ID existent.
Il faut donc choisir si le comptage des utilisateurs doit se baser sur le USER_ID (vue technique) ou sur le LOCAL_IDENTIFIER (vue client logique).


3. Indicateurs dâ€™activitÃ© limitÃ©s :

NB_LOG_TOTAL reprÃ©sente les connexions cumulÃ©es depuis la crÃ©ation du compte, pas sur une pÃ©riode donnÃ©e.

NB_LOG_30DAYS ne donne quâ€™une vision ponctuelle.
Pour estimer une activitÃ© trimestrielle, il faudrait disposer de plusieurs extractions consÃ©cutives.





---

5. Structures et ModÃ¨les DÃ©tectÃ©s

Lâ€™analyse rÃ©vÃ¨le les schÃ©mas suivants :

Un ENTITY_ID correspond gÃ©nÃ©ralement Ã  un MOM unique et un LOCAL_IDENTIFIER unique, mais peut regrouper plusieurs USER_ID.

Un USER_ID peut Ãªtre rattachÃ© Ã  plusieurs ENTITY_ID et LOCAL_IDENTIFIER, reflÃ©tant des droits multi-entitÃ©s (cas des utilisateurs de groupes).

Les dates de crÃ©ation dans le fichier comptes progressent de maniÃ¨re logique, confirmant la continuitÃ© client au fil du temps.



---

6. Recommandations OpÃ©rationnelles

1. Adopter le LOCAL_IDENTIFIER comme clÃ© de correspondance principale entre les deux fichiers, tout en le validant dans le pÃ©rimÃ¨tre de chaque ENTITY_ID pour Ã©viter les chevauchements entre entitÃ©s.


2. Ã‰liminer les doublons en consolidant les multiples USER_ID rattachÃ©s Ã  un mÃªme LOCAL_IDENTIFIER afin de reconstruire une vision client unifiÃ©e.


3. Ã‰tablir une cartographie complÃ¨te des correspondances entre utilisateurs et comptes :

utilisateurs sans compte,

comptes orphelins,

utilisateurs multi-entitÃ©s.



4. Mettre Ã  jour la base Xiscash en intÃ©grant les LOCAL_IDENTIFIER retrouvÃ©s via la base RMPM et en documentant les quatre cas restants non rÃ©solus aprÃ¨s vÃ©rification AMPM Web.


5. CrÃ©er un indicateur de cohÃ©rence temporelle pour identifier les comptes anciens (crÃ©Ã©s avant 2023) sans activitÃ© utilisateur rÃ©cente, et les utilisateurs actifs (fÃ©vrier 2025) sans compte associÃ©.


6. Standardiser les rÃ¨gles de crÃ©ation et de rattachement des utilisateurs dans Xiscash afin dâ€™Ã©viter les multiplicitÃ©s dâ€™identifiants entre entitÃ©s.


7. Mettre en place un tableau de bord de suivi de qualitÃ© de donnÃ©es, regroupant :

taux dâ€™utilisateurs sans compte,

taux de comptes orphelins,

doublons dÃ©tectÃ©s,

cohÃ©rence entre ENTITY_ID et LOCAL_IDENTIFIER,

activitÃ© utilisateur (connexion, derniÃ¨re date, etc.).





---

Souhaites-tu que je te le mette en version Word modifiable (mise en page professionnelle avec titres hiÃ©rarchisÃ©s, en-tÃªte et pied de page normalisÃ©s) avant de gÃ©nÃ©rer la version PDF officielle ?

