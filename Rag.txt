Objet : Demande de gravure de fichiers zippÃ©s

Bonjour lâ€™Ã©quipe support,

Je vous prie de bien vouloir graver les deux fichiers zippÃ©s disponibles aux liens suivants :

[Lien fichier 1]
[Lien fichier 2]

Ce sont les deux dossiers L Ba dont vous avez discutÃ© intensÃ©ment avec Omar hier.

N'hÃ©sitez pas Ã  me contacter si vous avez besoin dâ€™informations supplÃ©mentaires.

Merci dâ€™avance pour votre aide.

Cordialement,
[Votre nom]



def collect_excel_files(folder):
    return [
        str(path) for path in Path(folder).rglob("*")
        if path.suffix.lower() == ".xlsx"
    ]


import xlrd
import openpyxl
from openpyxl import Workbook
from pathlib import Path

def convert_xls_to_xlsx(xls_path):
    wb_xls = xlrd.open_workbook(xls_path)
    wb_xlsx = Workbook()
    sheet_xlsx = wb_xlsx.active

    sheet_xls = wb_xls.sheet_by_index(0)

    for row in range(sheet_xls.nrows):
        for col in range(sheet_xls.ncols):
            sheet_xlsx.cell(row=row+1, column=col+1).value = sheet_xls.cell_value(row, col)

    new_path = Path(xls_path).with_suffix('.xlsx')
    wb_xlsx.save(new_path)
    return str(new_path)



for csv_col, (field_key, yn_val) in csv_column_map.items():
    if "yn" in field_key:
        yes_col = header_map.get(f"{field_key}_yes")
        no_col = header_map.get(f"{field_key}_no")

        if yes_col and no_col:
            yes_cell = get_writable_cell(ws, row_num, yes_col)
            no_cell = get_writable_cell(ws, row_num, no_col)

            if matched:
                val = csv_df.at[rc_key, csv_col]
                if isinstance(val, str) and val.strip().upper() == "X":
                    if yn_val == "Ù†Ø¹Ù…":
                        yes_cell.value = "/"
                    elif yn_val == "Y":
                        no_cell.value = "/"
                    updated = True
                else:
                    if not yes_cell.value and not no_cell.value:
                        no_cell.value = "/"
                        updated = True

    elif "date" in field_key:
        # âœ… FIX: Lookup column first
        date_col = header_map.get(field_key) or header_map.get(field_key.replace(" ", "_"))

        if matched and date_col:
            date_val = csv_df.at[rc_key, csv_col]
            if isinstance(date_val, pd.Series):
                date_val = date_val.iloc[0]

            if date_val and str(date_val).strip():
                date_cell = get_writable_cell(ws, row_num, date_col)
                if not str(date_cell.value).strip():
                    date_cell.value = date_val
                    updated = True


elif "date" in field_key:
    date_col = header_map.get(field_key) or header_map.get(field_key.replace(" ", "_"))

if isinstance(date_val, pd.Series):
    date_val = date_val.iloc[0]
if date_val and str(date_val).strip():
    date_cell = get_writable_cell(ws, row_num, date_col)
    if not str(date_cell.value).strip():
        date_cell.value = date_val
        updated = True



rc_key = str(rc).strip()
matched = rc_key in csv_df.index

if rc is None or str(rc).strip() == "":
    row_num += 1
    empty_count += 1
    if empty_count > 100:
        break
    continue




import os
import pandas as pd
from openpyxl import load_workbook
from openpyxl.cell.cell import MergedCell
from pathlib import Path

def get_writable_cell(ws, row, col):
    cell = ws.cell(row=row, column=col)
    if isinstance(cell, MergedCell):
        for merged in ws.merged_cells.ranges:
            if (row, col) in merged.cells:
                return ws.cell(row=merged.min_row, column=merged.min_col)
    return cell

def normalize_arabic(text):
    if not text:
        return ""
    return str(text).replace("ÛŒ", "ÙŠ").replace("Ùƒ", "Ùƒ").replace("â€Œ", "").replace("-", "") \
        .replace("\u200f", "").replace("\u200e", "").strip()

def find_merged_column_by_text(ws, header_lines, target_text):
    target_text = normalize_arabic(target_text)
    for col in range(1, ws.max_column + 1):
        header_parts = []
        for row in range(1, header_lines + 1):
            val = ws.cell(row=row, column=col).value
            if val:
                header_parts.append(normalize_arabic(val))
        full_header = "".join(header_parts)
        if target_text in full_header:
            return col
    return None

def collect_excel_files(folder):
    return list(Path(folder).rglob("*.xlsx"))

def fill_excel_from_csv(csv_path, excel_folder, output_folder):
    os.makedirs(output_folder, exist_ok=True)

    rc_cols = [
        "Ø±Ù‚Ù… Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ¬Ø§Ø±ÙŠ", "NÂ° du registre du commerce",
        "Ø±Ù‚Ù… Ø§Ù„Ø³Ø¬Ù„ d'inscription", "N"
    ]

    loan_yn_header = "Ù‡Ù„ Ø§Ø³ØªÙØ§Ø¯ Ø§Ù„Ù…ØªØ¹Ø§Ù…Ù„ Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ Ù…Ù† Ù‚Ø±Ø¶ Ø¨Ù†ÙƒÙŠ"
    import_yn_header = "Ù‡Ù„ Ù‚Ø§Ù… Ø§Ù„Ù…ØªØ¹Ø§Ù…Ù„ Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ Ø¨ØªÙˆØ·ÙŠÙ† Ø¨Ù†ÙƒÙŠ Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ø³ØªÙŠØ±Ø§Ø¯"
    loan_date_header = "ØªØ§Ø±ÙŠØ® Ø¢Ø®Ø± Ø§Ø³ØªÙØ§Ø¯Ø© Ù…Ù† Ù‚Ø±Ø¶ Ø¨Ù†ÙƒÙŠ"
    import_date_header = "ØªØ§Ø±ÙŠØ® Ø¢Ø®Ø± ØªÙˆØ·ÙŠÙ† Ø¨Ù†ÙƒÙŠ Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ø³ØªÙŠØ±Ø§Ø¯"

    csv_column_map = {
        "beneficiaire credit Oui": ("loan_yn", "Ù†Ø¹Ù…"),
        "beneficiaire credit Non": ("loan_yn", "Ù„Ø§"),
        "Operation import Oui": ("import_yn", "Ù†Ø¹Ù…"),
        "Operation import Non": ("import_yn", "Ù„Ø§"),
        "Derniere date effet crÃ©dit": ("loan date", None),
        "Derniere date import": ("import date", None)
    }

    csv_df = pd.read_csv(csv_path, dtype=str).fillna("")
    if "Registre_commerce" not in csv_df.columns:
        print("ğŸš« 'Registre_commerce' column missing in CSV.")
        return

    csv_df.set_index("Registre_commerce", inplace=True)

    excel_files = collect_excel_files(excel_folder)

    for file_path in excel_files:
        input_path = str(file_path)
        output_path = os.path.join(output_folder, os.path.relpath(input_path, excel_folder))
        os.makedirs(os.path.dirname(output_path), exist_ok=True)

        print(f"ğŸ“‚ Processing: {input_path}")

        wb = load_workbook(input_path)
        updated = False

        for sheetname in wb.sheetnames:
            ws = wb[sheetname]
            header_row = None
            header_map = {}

            # Detect header
            for i in range(1, 51):
                row_vals = [str(cell.value).strip() if cell.value else "" for cell in ws[i]]
                for idx, val in enumerate(row_vals):
                    if val in rc_cols:
                        header_row = i
                        header_map["Registre_commerce"] = idx + 1
                        break
                if header_row:
                    break

            if not header_row:
                print(f"âš ï¸ No RC column found in {input_path} / Sheet: {sheetname}")
                continue

            # Detect column positions for dates and booleans
            header_map["loan date"] = find_merged_column_by_text(ws, 10, loan_date_header)
            header_map["import date"] = find_merged_column_by_text(ws, 10, import_date_header)

            for merged in ws.merged_cells.ranges:
                cell = ws.cell(row=header_row, column=merged.min_col)
                val = str(cell.value).strip() if cell.value else ""
                if loan_yn_header in val:
                    header_map["loan_yn_yes"] = merged.min_col
                    header_map["loan_yn_no"] = merged.min_col + 1
                elif import_yn_header in val:
                    header_map["import_yn_yes"] = merged.min_col
                    header_map["import_yn_no"] = merged.min_col + 1

            rc_col = header_map.get("Registre_commerce")
            if not rc_col:
                print(f"âš ï¸ Invalid or missing RC column in: {input_path}")
                continue

            row_num = header_row + 1
            empty_count = 0

            while row_num <= ws.max_row:
                rc_cell = ws.cell(row=row_num, column=rc_col)
                rc = rc_cell.value

                if rc is None or str(rc).strip() == "":
                    row_num += 1
                    empty_count += 1
                    if empty_count > 100:
                        break
                    continue

                empty_count = 0
                rc_key = str(rc).strip()
                matched = rc_key in csv_df.index

                for csv_col, (field_key, yn_val) in csv_column_map.items():
                    if "yn" in field_key:
                        yes_col = header_map.get(f"{field_key}_yes")
                        no_col = header_map.get(f"{field_key}_no")
                        if yes_col and no_col:
                            yes_cell = get_writable_cell(ws, row_num, yes_col)
                            no_cell = get_writable_cell(ws, row_num, no_col)

                            if matched:
                                val = csv_df.at[rc_key, csv_col]
                                if isinstance(val, str) and val.strip().upper() == "X":
                                    if yn_val == "Ù†Ø¹Ù…":
                                        yes_cell.value = "/"
                                    elif yn_val == "Ù„Ø§":
                                        no_cell.value = "/"
                                    updated = True
                                else:
                                    if not yes_cell.value and not no_cell.value:
                                        no_cell.value = "/"
                                        updated = True
                    elif "date" in field_key:
                        date_col = header_map.get(field_key)
                        if matched and date_col:
                            date_val = csv_df.at[rc_key, csv_col]
                            if isinstance(date_val, pd.Series):
                                date_val = date_val.iloc[0]
                            if date_val and str(date_val).strip():
                                date_cell = get_writable_cell(ws, row_num, date_col)
                                if not str(date_cell.value).strip():
                                    date_cell.value = date_val
                                    updated = True

                row_num += 1

        wb.save(output_path)
        if updated:
            print(f"âœ… Saved: {output_path}")
        else:
            print(f"ğŸ“„ No updates made: {output_path}")





rc_col = header_map.get("Registre_commerce")
if not rc_col or rc_col < 1:
    print(f"âŒ 'Registre_commerce' column not found or invalid in: {input_path}")
    continue

row_num = header_row + 1
empty_count = 0

while row_num <= ws.max_row:
    rc_cell = ws.cell(row=row_num, column=rc_col)
    rc = rc_cell.value

    if rc is None or str(rc).strip() == "":
        row_num += 1
        empty_count += 1
        if empty_count > 100:
            break
        continue

    empty_count = 0
    rc_key = str(rc).strip()
    matched = rc_key in csv_df.index

    # ... your processing logic ...

    row_num += 1


row_num = header_row + 1
empty_count = 0

while row_num <= ws.max_row:
    rc_cell = ws.cell(row=row_num, column=header_map["Registre commerce"] + 1)
    rc = rc_cell.value

    # Skip if RC is empty
    if rc is None or str(rc).strip() == "":
        row_num += 1
        empty_count += 1
        if empty_count > 100:  # If 100 consecutive empty RCs, stop
            break
        continue

    empty_count = 0  # Reset when we find a non-empty RC
    rc_key = str(rc).strip()
    matched = rc_key in csv_df.index

    # (keep the rest of your processing code here...)

    row_num += 1



import os
import pandas as pd
from pathlib import Path
from openpyxl import load_workbook
from openpyxl.cell.cell import MergedCell

def get_writable_cell(ws, row, col):
    """Get writable cell, handling merged cells"""
    cell = ws.cell(row=row, column=col)
    
    if isinstance(cell, MergedCell):
        for merged in ws.merged_cells.ranges:
            if (row, col) in merged.cells:
                return ws.cell(row=merged.min_row, column=merged.min_col)
    
    return cell

def normalize_arabic(text):
    """Normalize Arabic text by removing extra characters"""
    if not text:
        return ""
    
    return (str(text)
            .replace("ÛŒ", "ÛŒ")  # Persian to Arabic
            .replace("Ù€", "")  # tatweel
            .replace("\u200f", "")  # Right-to-left mark
            .replace("\u200e", "")  # Left-to-right mark
            .replace("-", "")
            .strip())

def find_merged_column_by_text(ws, header_lines, target_text):
    """Find column containing target text in merged headers"""
    target_text = normalize_arabic(target_text)
    
    for col in range(1, ws.max_column + 1):
        header_parts = []
        
        for row in range(1, header_lines + 1):
            val = ws.cell(row=row, column=col).value
            if val:
                header_parts.append(normalize_arabic(val))
        
        full_header = "".join(header_parts)
        
        if target_text in full_header:
            return col
    
    return None

def collect_excel_files(folder):
    """Collect all Excel files from folder"""
    return list(Path(folder).rglob("*.xlsx"))

def fill_excel_from_csv(csv_path, excel_folder, output_folder):
    """Main function to process Excel files based on CSV data"""
    os.makedirs(output_folder, exist_ok=True)
    
    # Header mappings
    loan_date_header = "ØªØ§Ø±ÛŒØ® Ø¢Ø®Ø± Ø¹Ù…Ù„ÙŠØ© Ù‚Ø±Ø¶"
    import_date_header = "ØªØ§Ø±ÛŒØ® Ø¢Ø®Ø± Ø¹Ù…Ù„ÙŠØ© Ø§Ø³ØªÙŠØ±Ø§Ø¯"
    loan_yn_header = "Ù‡Ù„ Ø§Ø³ØªÙØ§Ø¯ Ø§Ù„Ù…ØªØ¹Ø§Ù…Ù„ Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ Ù…Ù† Ù‚Ø±Ø¶ Ø¨Ù†ÙƒÙŠ"
    import_yn_header = "Ù‡Ù„ Ù‚Ø§Ù… Ø§Ù„Ù…ØªØ¹Ø§Ù…Ù„ Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ Ø¨Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ø³ØªÙŠØ±Ø§Ø¯"
    
    # CSV column mapping
    csv_column_map = {
        "beneficiaire_credit": ("loan_yn", "Ù†Ø¹Ù…"),
        "beneficiaire_credit_no": ("loan_yn", "Ù„Ø§"),
        "operation_import": ("import_yn", "Ù†Ø¹Ù…"),
        "operation_import_no": ("import_yn", "Ù„Ø§"),
        "derniere_date_credit": ("loan_date", None),
        "derniere_date_import": ("import_date", None)
    }
    
    # Check if Registre commerce column exists in CSV
    if "Registre_commerce" not in csv_column_map:
        print("âŒ Registre commerce column missing in CSV.")
        return
    
    # Read CSV
    csv_df = pd.read_csv(csv_path, dtype=str).fillna("")
    csv_df = csv_df.set_index("Registre_commerce", inplace=False)
    
    # Process Excel files
    excel_files = collect_excel_files(excel_folder)
    
    for file_path in excel_files:
        input_path = str(file_path)
        output_path = os.path.join(output_folder, os.path.relpath(input_path, excel_folder))
        
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        wb = load_workbook(input_path)
        updated = False
        
        for sheet_name in wb.sheetnames:
            ws = wb[sheet_name]
            header_row = None
            header_map = {}
            
            # Find header row with "Registre commerce"
            for i in range(1, 11):  # Check first 10 rows
                row_vals = [str(cell.value).strip() if cell.value else "" for cell in ws[i]]
                
                for idx, val in enumerate(row_vals):
                    if "Registre commerce" in val:
                        header_row = i
                        header_map["Registre_commerce"] = idx + 1
                        break
                
                if header_row:
                    break
            
            if not header_row:
                print(f"âŒ No RC column found in {input_path} / Sheet ({sheet_name})")
                continue
            
            # Find date columns
            header_map["loan_date"] = find_merged_column_by_text(ws, 10, loan_date_header)
            header_map["import_date"] = find_merged_column_by_text(ws, 10, import_date_header)
            
            # Find yes/no columns for loan and import
            for merged in ws.merged_cells.ranges:
                cell = ws.cell(row=header_row, column=merged.min_col)
                if not cell.value:
                    continue
                
                val = str(cell.value).strip()
                
                if loan_yn_header in val:
                    header_map["loan_yn_yes"] = merged.min_col
                    header_map["loan_yn_no"] = merged.min_col + 1
                elif import_yn_header in val:
                    header_map["import_yn_yes"] = merged.min_col
                    header_map["import_yn_no"] = merged.min_col + 1
            
            # Process data rows
            row_num = header_row + 1
            max_rows = ws.max_row
            
            while row_num <= max_rows:
                rc_cell = ws.cell(row=row_num, column=header_map["Registre_commerce"])
                rc = rc_cell.value
                
                # Skip empty rows but continue processing
                if rc is None or str(rc).strip() == "":
                    row_num += 1
                    continue
                
                rc_key = str(rc).strip()
                matched = rc_key in csv_df.index
                
                # Process each CSV column mapping
                for csv_col, (field_key, yn_val) in csv_column_map.items():
                    if "yn" in field_key:
                        yes_col = header_map.get(f"{field_key}_yes")
                        no_col = header_map.get(f"{field_key}_no")
                        
                        if yes_col and no_col:
                            yes_cell = get_writable_cell(ws, row_num, yes_col)
                            no_cell = get_writable_cell(ws, row_num, no_col)
                            
                            if matched:
                                val = csv_df.at[rc_key, csv_col]
                                if isinstance(val, str) and val.strip().upper() == "X":
                                    if yn_val == "Ù†Ø¹Ù…":
                                        yes_cell.value = "/"
                                    elif yn_val == "Ù„Ø§":
                                        no_cell.value = "/"
                                    updated = True
                            else:
                                if not yes_cell.value and not no_cell.value:
                                    no_cell.value = "/"
                                    updated = True
                    
                    elif "date" in field_key:
                        date_col = header_map.get(field_key)
                        if matched and date_col:
                            date_val = csv_df.at[rc_key, csv_col]
                            if isinstance(date_val, pd.Series):
                                date_val = date_val.iloc[0]
                            
                            if date_val:
                                date_cell = get_writable_cell(ws, row_num, date_col)
                                if not date_cell.value:
                                    date_cell.value = date_val
                                    updated = True
                
                row_num += 1
        
        # Save workbook
        wb.save(output_path)
        
        if updated:
            print(f"âœ… Saved: {output_path}")
        else:
            print(f"â„¹ï¸  No updates made: {output_path}")

# Example usage
if __name__ == "__main__":
    csv_path = "data.csv"
    excel_folder = "excel_files"
    output_folder = "output"
    
    fill_excel_from_csv(csv_path, excel_folder, output_folder)
