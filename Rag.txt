import os
import pandas as pd

# Root folder where your Excel files are located
root_folder = "/mnt/sheets/Liste des personnes physiques-morales non localiser"

# Define the list of target column names
target_columns = ["N° d'inscription", "N°", "رقم التسجيل", "Numéro", "Client ID", "Identifiant", "رقم"]

# Container for all extracted data
all_data = []

# Loop through all subdirectories and files
for dirpath, dirnames, filenames in os.walk(root_folder):
    for file in filenames:
        if file.endswith((".xlsx", ".xls")) and not file.startswith("~$"):  # Skip temp files
            file_path = os.path.join(dirpath, file)
            try:
                xls = pd.ExcelFile(file_path)
                for sheet_name in xls.sheet_names:
                    try:
                        df = pd.read_excel(file_path, sheet_name=sheet_name, dtype=str)
                        df.columns = df.columns.str.strip()  # Strip spaces from column names

                        # Find which target columns exist in this sheet
                        available_cols = [col for col in df.columns if col in target_columns]

                        if available_cols:
                            extracted = df[available_cols].copy()
                            extracted["SheetName"] = sheet_name
                            extracted["FileName"] = file
                            extracted["FilePath"] = file_path
                            all_data.append(extracted)

                    except Exception as e:
                        print(f"Error reading sheet '{sheet_name}' in '{file}': {e}")
            except Exception as e:
                print(f"Error opening Excel file '{file}': {e}")

# Combine and export to Excel
if all_data:
    final_df = pd.concat(all_data, ignore_index=True)
    output_path = "/mnt/data/consolidated_output.xlsx"
    final_df.to_excel(output_path, index=False)
    print(f"Data consolidated into: {output_path}")
else:
    print("No data extracted. Check column names and file formats.")






import os
import pandas as pd

base_folder = "/mnt/data/YOUR_FOLDER_NAME"

sheet_info = []

for root, dirs, files in os.walk(base_folder):
    for file in files:
        if file.endswith((".xlsx", ".xls")):
            file_path = os.path.join(root, file)
            try:
                xls = pd.ExcelFile(file_path)
                for sheet_name in xls.sheet_names:
                    try:
                        df = pd.read_excel(xls, sheet_name=sheet_name)
                        df.columns = df.columns.str.strip()
                        columns_list = list(df.columns)

                        sheet_info.append({
                            "File": file,
                            "Sheet": sheet_name,
                            "Columns": columns_list
                        })

                    except Exception as e:
                        print(f"Error reading sheet '{sheet_name}' in file '{file}': {e}")
            except Exception as e:
                print(f"Error opening Excel file '{file}': {e}")

# Convert to DataFrame for display or export
sheet_info_df = pd.DataFrame(sheet_info)

# Show the dataframe
print(sheet_info_df)

# Optionally save to Excel
sheet_info_df.to_excel("/mnt/data/All_Sheets_Columns_Info.xlsx", index=False)
print("Saved all sheets and columns info to: All_Sheets_Columns_Info.xlsx")




import os
import pandas as pd
from tqdm import tqdm
from collections import Counter

base_folder = "/mnt/data/YOUR_FOLDER_NAME"

# This is now for logging and summary only
target_columns = ["N° d'inscription", "N°", "رقم التسجيل", "رقم", "الرقم", 
                  "رقم العميل", "رقم حساب", "Numéro d’identification", 
                  "N° identifiant", "Identifiant", "Client ID", "Registration Number"]

all_data = []
sheet_summary = []
column_summary = []

for root, dirs, files in os.walk(base_folder):
    for file in files:
        if file.endswith(".xlsx") or file.endswith(".xls"):
            file_path = os.path.join(root, file)
            try:
                xls = pd.ExcelFile(file_path)
                for sheet_name in xls.sheet_names:
                    try:
                        df = pd.read_excel(xls, sheet_name=sheet_name)
                        df.columns = df.columns.str.strip()

                        # Log all columns
                        column_summary.append({
                            "File": file,
                            "Sheet": sheet_name,
                            "Columns": list(df.columns)
                        })

                        # Save sheet info
                        sheet_summary.append({
                            "File": file,
                            "Sheet": sheet_name
                        })

                        # Append the full sheet + metadata
                        df["Source_File"] = file
                        df["Source_Sheet"] = sheet_name
                        df["File_Path"] = file_path
                        all_data.append(df)

                    except Exception as e:
                        print(f"Error reading sheet '{sheet_name}' in file '{file}': {e}")
            except Exception as e:
                print(f"Error opening Excel file '{file}': {e}")

# Combine all
if all_data:
    combined_df = pd.concat(all_data, ignore_index=True)
    combined_df.to_excel("/mnt/data/Combined_All_Data.xlsx", index=False)
    print("Saved full combined data to: Combined_All_Data.xlsx")
else:
    print("No valid sheets found.")

# Sheet summary
pd.DataFrame(sheet_summary).to_excel("/mnt/data/All_Sheets_Info.xlsx", index=False)
print("Saved sheet info to: All_Sheets_Info.xlsx")

# Unique columns
all_columns = []
for entry in column_summary:
    all_columns.extend(entry["Columns"])

unique_columns = sorted(set([str(col).strip() for col in all_columns]))
pd.DataFrame(unique_columns, columns=["Unique Column Names"]).to_excel(
    "/mnt/data/Unique_Columns_Across_Sheets.xlsx", index=False
)
print("Saved all unique column names to: Unique_Columns_Across_Sheets.xlsx")

# Column frequency
col_counter = Counter([str(col).strip() for col in all_columns])
col_freq_df = pd.DataFrame(col_counter.items(), columns=["Column Name", "Frequency"])
col_freq_df.sort_values(by="Frequency", ascending=False).to_excel(
    "/mnt/data/Column_Frequencies.xlsx", index=False
)
print("Saved column frequency counts to: Column_Frequencies.xlsx")






import os
import pandas as pd

# Path to your root directory
root_folder = "/mnt/data/YOUR_FOLDER_NAME"  # <-- Replace with your actual folder name in Domino

# Arabic column names you're interested in
target_columns = ["ن°", "ن° التسجيل"]  # Adjust if necessary

# Containers for final output and sheet list
all_data = []
sheet_summary = []

# STEP 1: Walk through all Excel files and list file + sheet names
for dirpath, dirnames, filenames in os.walk(root_folder):
    for filename in filenames:
        if filename.endswith((".xlsx", ".xls")) and not filename.startswith("~$"):
            file_path = os.path.join(dirpath, filename)
            try:
                excel = pd.ExcelFile(file_path)
                for sheet in excel.sheet_names:
                    sheet_summary.append({
                        "File Name": filename,
                        "Sheet Name": sheet,
                        "File Path": file_path
                    })
            except Exception as e:
                print(f"Error reading sheet names from {filename}: {e}")

# STEP 2: Display the table of all file and sheet names
sheet_df = pd.DataFrame(sheet_summary)
print("List of all Excel files and their sheet names:")
display(sheet_df)  # For Domino Notebook environment

# STEP 3: Now process and extract the Arabic columns
for entry in sheet_summary:
    try:
        df = pd.read_excel(entry["File Path"], sheet_name=entry["Sheet Name"])
        if all(col in df.columns for col in target_columns):
            selected = df[target_columns].copy()
            selected["File Name"] = entry["File Name"]
            selected["Sheet Name"] = entry["Sheet Name"]
            selected["File Path"] = entry["File Path"]
            all_data.append(selected)
    except Exception as e:
        print(f"Error reading data from {entry['File Name']} - Sheet: {entry['Sheet Name']} | {e}")

# STEP 4: Combine and save
if all_data:
    final_df = pd.concat(all_data, ignore_index=True)
    output_file = "/mnt/data/Consolidated_Arabic_Columns.xlsx"
    final_df.to_excel(output_file, index=False)
    print(f"\nConsolidated data saved to: {output_file}")
else:
    print("No valid data with the target columns found.")






import os
import pandas as pd

# Path to your main folder in Domino
root_folder = "/mnt/data/YOUR_FOLDER_NAME"  # Replace with actual folder name

# Arabic column names (adjust based on exact spelling/spacing in your files)
target_columns = ["ن°", "ن° التسجيل"]  # Replace with exact column names if needed

all_data = []

# Walk through all subdirectories and files
for dirpath, dirnames, filenames in os.walk(root_folder):
    for filename in filenames:
        if filename.endswith((".xlsx", ".xls")) and not filename.startswith("~$"):
            file_path = os.path.join(dirpath, filename)
            try:
                excel = pd.ExcelFile(file_path)
                for sheet in excel.sheet_names:
                    try:
                        df = pd.read_excel(file_path, sheet_name=sheet)

                        # Check and extract the desired columns
                        if all(col in df.columns for col in target_columns):
                            selected = df[target_columns].copy()
                            selected["File Name"] = filename
                            selected["Sheet Name"] = sheet
                            selected["File Path"] = file_path
                            all_data.append(selected)
                    except Exception as sheet_err:
                        print(f"Failed to read sheet '{sheet}' in '{filename}': {sheet_err}")
            except Exception as file_err:
                print(f"Could not open file '{filename}': {file_err}")

# Combine and export
if all_data:
    final_df = pd.concat(all_data, ignore_index=True)
    output_file = "/mnt/data/Consolidated_Arabic_Columns.xlsx"
    final_df.to_excel(output_file, index=False)
    print(f"All data consolidated! Saved to: {output_file}")
else:
    print("No valid data found.")






import os

# Path to your main folder
root_folder = "/mnt/data/your_main_folder"  # Replace with your actual path

# Supported Excel extensions
excel_files = []

for dirpath, dirnames, filenames in os.walk(root_folder):
    for file in filenames:
        if file.endswith((".xlsx", ".xls")) and not file.startswith("~$"):  # Exclude temp files
            full_path = os.path.join(dirpath, file)
            excel_files.append(full_path)

# Display all Excel files found
for file in excel_files:
    print(file)

print(f"\nTotal Excel files found: {len(excel_files)}")




import os
import pandas as pd

# Set your main folder path
root_folder = "/mnt/data/your_main_folder"  # <-- Update this path

# Target sheet names and columns
target_sheets = ['pm', 'pp']
target_columns = ["N° d'inscription", "N°"]

# Container for data
all_data = []

# Walk through subdirectories
for dirpath, dirnames, filenames in os.walk(root_folder):
    for file in filenames:
        if file.endswith(('.xlsx', '.xls')) and not file.startswith('~$'):  # Skip temp files
            file_path = os.path.join(dirpath, file)
            try:
                xls = pd.ExcelFile(file_path)
                for sheet in target_sheets:
                    if sheet in xls.sheet_names:
                        try:
                            df = pd.read_excel(file_path, sheet_name=sheet, dtype=str)
                            available_cols = [col for col in target_columns if col in df.columns]
                            if available_cols:
                                extracted = df[available_cols].copy()
                                extracted["FileName"] = file
                                extracted["SheetName"] = sheet
                                extracted["FilePath"] = file_path
                                all_data.append(extracted)
                        except Exception as e:
                            print(f"Error reading sheet '{sheet}' in {file}: {e}")
            except Exception as e:
                print(f"Error opening {file}: {e}")

# Combine and export
if all_data:
    final_df = pd.concat(all_data, ignore_index=True)
    output_path = "/mnt/data/consolidated_output.xlsx"
    final_df.to_excel(output_path, index=False)
    print(f"Data consolidated into: {output_path}")
else:
    print("No data extracted. Check sheet names and column availability.")




import os
import pandas as pd

# Folder containing Excel files
folder_path = "/mnt/data/your_excel_folder/"  # Update path as needed

# Target sheets and columns
target_sheets = ['pm', 'pp']
target_columns = ["N° d'inscription", "N°"]

# Output list
all_data = []

# Loop through each file in the directory
for root, dirs, files in os.walk(folder_path):
    for file in files:
        if file.endswith('.xlsx') or file.endswith('.xls'):
            file_path = os.path.join(root, file)
            try:
                xls = pd.ExcelFile(file_path)
                for sheet_name in target_sheets:
                    if sheet_name in xls.sheet_names:
                        try:
                            df = pd.read_excel(file_path, sheet_name=sheet_name)
                            cols = [col for col in target_columns if col in df.columns]
                            if cols:
                                temp_df = df[cols].copy()
                                temp_df['FileName'] = file
                                temp_df['SheetName'] = sheet_name
                                temp_df['FilePath'] = file_path
                                all_data.append(temp_df)
                        except Exception as e:
                            print(f"Failed to read sheet '{sheet_name}' in file '{file}': {e}")
            except Exception as e:
                print(f"Failed to read file '{file}': {e}")

# Concatenate all data
if all_data:
    final_df = pd.concat(all_data, ignore_index=True)
    output_file = "/mnt/data/consolidated_output.xlsx"
    final_df.to_excel(output_file, index=False)
    print(f"Consolidated file saved to: {output_file}")
else:
    print("No data found in target sheets and columns.")





import os
import pandas as pd

# Define directory where your Excel files are stored
excel_dir = "/mnt/data/your_excel_folder/"

# Columns you want to extract (update based on real names)
target_columns = ['Client Name', 'Account Number']  # Adjust to your need

# Placeholder for all rows
all_data = []

# Walk through all Excel files
for filename in os.listdir(excel_dir):
    if filename.endswith('.xlsx') or filename.endswith('.xls'):
        file_path = os.path.join(excel_dir, filename)
        try:
            xls = pd.ExcelFile(file_path)
            for sheet in xls.sheet_names:
                try:
                    df = pd.read_excel(file_path, sheet_name=sheet)
                    # Filter by existing columns only
                    cols = [col for col in target_columns if col in df.columns]
                    if cols:
                        df_filtered = df[cols].copy()
                        df_filtered['SourceFile'] = filename
                        df_filtered['SheetName'] = sheet
                        all_data.append(df_filtered)
                except Exception as e:
                    print(f"Error reading sheet {sheet} in {filename}: {e}")
        except Exception as e:
            print(f"Error reading file {filename}: {e}")

# Combine everything into one DataFrame
final_df = pd.concat(all_data, ignore_index=True)

# Save final consolidated file
output_path = "/mnt/data/consolidated_output.xlsx"
final_df.to_excel(output_path, index=False)
print(f"Saved consolidated file to: {output_path}")




import pandas as pd
from ayx import Alteryx

# Read the incoming directory file list
df = Alteryx.read("#1")

output = []

# Loop over each Excel file
for path in df['FullPath']:
    if path.endswith('.xlsx') or path.endswith('.xls'):
        try:
            xls = pd.ExcelFile(path)
            for sheet in xls.sheet_names:
                output.append({
                    'FullPath': path,
                    'SheetName': sheet
                })
        except Exception as e:
            print(f"Error reading {path}: {e}")
    else:
        print(f"Skipped: {path}")

# Create a DataFrame from the collected paths and sheets
output_df = pd.DataFrame(output)

# Construct valid metadata required by Alteryx
metadata = {
    'FullPath': {
        'type': 'V_WString',
        'size': 1000,
        'source': 'PythonTool',
        'description': 'Path of the Excel file'
    },
    'SheetName': {
        'type': 'V_WString',
        'size': 255,
        'source': 'PythonTool',
        'description': 'Sheet name in Excel file'
    }
}

# Write the data to the output anchor
Alteryx.write(output_df, 1, metadata)






import pandas as pd
from ayx import Alteryx

df = Alteryx.read("#1")

output = []

for path in df['FullPath']:
    if path.endswith('.xlsx') or path.endswith('.xls'):
        try:
            xls = pd.ExcelFile(path)
            for sheet in xls.sheet_names:
                output.append({
                    'FullPath': path,
                    'SheetName': sheet
                })
        except Exception as e:
            print(f"Error reading {path}: {e}")
    else:
        print(f"Skipped (not Excel): {path}")

output_df = pd.DataFrame(output)

# Define proper metadata for Alteryx output
metadata = {
    'FullPath': {
        'type': 'V_WString',
        'size': 1000,
        'source': 'PythonTool',
        'description': 'Full file path of Excel'
    },
    'SheetName': {
        'type': 'V_WString',
        'size': 255,
        'source': 'PythonTool',
        'description': 'Sheet name inside Excel file'
    }
}

Alteryx.write(output_df, 1, metadata)





import pandas as pd
from ayx import Alteryx
import os

df = Alteryx.read("#1")

output = []

for path in df['FullPath']:
    if path.endswith('.xlsx') or path.endswith('.xls'):
        try:
            xls = pd.ExcelFile(path)
            for sheet in xls.sheet_names:
                output.append({
                    'FullPath': path,
                    'SheetName': sheet
                })
        except Exception as e:
            print(f"Error reading {path}: {e}")
    else:
        print(f"Skipped (not Excel): {path}")

# Create DataFrame
output_df = pd.DataFrame(output)

# Define metadata
metadata = {
    'FullPath': {
        'type': 'V_WString',
        'size': 500
    },
    'SheetName': {
        'type': 'V_WString',
        'size': 255
    }
}

Alteryx.write(output_df, 1, metadata)




import pandas as pd
import os
from ayx import Alteryx

# Read input data from Alteryx (coming from the Directory Tool)
df = Alteryx.read("#1")  # Make sure Python tool is connected to Directory Tool

output = []

for path in df['FullPath']:
    try:
        xls = pd.ExcelFile(path)
        for sheet in xls.sheet_names:
            output.append({
                'FullPath': path,
                'SheetName': sheet
            })
    except Exception as e:
        print(f"Error reading {path}: {e}")
        continue

# Output the sheet name and file path to next Alteryx tools
Alteryx.write(pd.DataFrame(output), 1)





[FullPath] + "|||SheetName=" + [SheetName]



InputPathWithSheet


import pandas as pd
from ayx import Alteryx

df = Alteryx.read("#1")  # From Directory Tool
output = []

for path in df['FullPath']:
    try:
        xls = pd.ExcelFile(path)
        for sheet in xls.sheet_names:
            output.append({
                'FullPath': path,
                'SheetName': sheet
            })
    except:
        pass

Alteryx.write(pd.DataFrame(output), 1)
